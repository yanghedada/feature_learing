{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import  load_digits\n",
    "x = load_digits().data\n",
    "y = load_digits().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train , x_test ,y_train , y_test = train_test_split(x,\n",
    "                                                      y,\n",
    "                                                      random_state=33,\n",
    "                                                     test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64) (450, 64) (1347,) (450,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape , y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.88      0.98      0.93        54\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       0.92      0.96      0.94        46\n",
      "          4       0.97      0.94      0.96        35\n",
      "          5       0.96      0.94      0.95        48\n",
      "          6       0.96      0.98      0.97        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       0.94      0.83      0.88        58\n",
      "          9       0.95      0.95      0.95        44\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        35\n",
      "          1       0.86      0.93      0.89        54\n",
      "          2       0.93      0.95      0.94        44\n",
      "          3       0.93      0.91      0.92        46\n",
      "          4       1.00      0.91      0.96        35\n",
      "          5       0.96      0.94      0.95        48\n",
      "          6       0.91      0.98      0.94        51\n",
      "          7       0.92      1.00      0.96        35\n",
      "          8       0.93      0.69      0.79        58\n",
      "          9       0.76      0.84      0.80        44\n",
      "\n",
      "avg / total       0.91      0.91      0.91       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier(alpha=0.5)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        35\n",
      "          1       0.86      0.93      0.89        54\n",
      "          2       0.93      0.95      0.94        44\n",
      "          3       0.93      0.91      0.92        46\n",
      "          4       1.00      0.91      0.96        35\n",
      "          5       0.96      0.94      0.95        48\n",
      "          6       0.91      0.98      0.94        51\n",
      "          7       0.92      1.00      0.96        35\n",
      "          8       0.93      0.69      0.79        58\n",
      "          9       0.76      0.84      0.80        44\n",
      "\n",
      "avg / total       0.91      0.91      0.91       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "clf  = RidgeClassifierCV(alphas=[0.001,0.1,0.5,1])\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.63      0.77        35\n",
      "          1       1.00      0.33      0.50        54\n",
      "          2       1.00      0.34      0.51        44\n",
      "          3       1.00      0.50      0.67        46\n",
      "          4       1.00      0.89      0.94        35\n",
      "          5       1.00      0.38      0.55        48\n",
      "          6       1.00      0.45      0.62        51\n",
      "          7       0.12      1.00      0.22        35\n",
      "          8       1.00      0.02      0.03        58\n",
      "          9       1.00      0.36      0.53        44\n",
      "\n",
      "avg / total       0.93      0.45      0.51       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf  = SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        35\n",
      "          1       0.91      0.98      0.95        54\n",
      "          2       0.98      1.00      0.99        44\n",
      "          3       0.96      0.96      0.96        46\n",
      "          4       0.94      0.94      0.94        35\n",
      "          5       0.96      0.92      0.94        48\n",
      "          6       0.96      0.98      0.97        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       0.96      0.84      0.90        58\n",
      "          9       0.91      0.95      0.93        44\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf  = LinearSVC()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.98      1.00      0.99        54\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       1.00      1.00      1.00        46\n",
      "          4       1.00      1.00      1.00        35\n",
      "          5       0.98      0.96      0.97        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       0.98      0.98      0.98        58\n",
      "          9       0.98      0.98      0.98        44\n",
      "\n",
      "avg / total       0.99      0.99      0.99       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf  = SVC(kernel='poly',degree=4)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        35\n",
      "          1       0.00      0.00      0.00        54\n",
      "          2       0.00      0.00      0.00        44\n",
      "          3       0.00      0.00      0.00        46\n",
      "          4       0.08      1.00      0.14        35\n",
      "          5       0.00      0.00      0.00        48\n",
      "          6       0.00      0.00      0.00        51\n",
      "          7       0.00      0.00      0.00        35\n",
      "          8       0.00      0.00      0.00        58\n",
      "          9       0.00      0.00      0.00        44\n",
      "\n",
      "avg / total       0.01      0.08      0.01       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf  = SVC(kernel='rbf',gamma=3,C=1)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        35\n",
      "          1       0.66      0.94      0.78        54\n",
      "          2       1.00      0.93      0.96        44\n",
      "          3       0.92      0.98      0.95        46\n",
      "          4       0.97      0.94      0.96        35\n",
      "          5       0.98      0.83      0.90        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       1.00      0.41      0.59        58\n",
      "          9       0.69      0.98      0.81        44\n",
      "\n",
      "avg / total       0.91      0.88      0.88       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.93      1.00      0.96        54\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       1.00      1.00      1.00        46\n",
      "          4       1.00      0.97      0.99        35\n",
      "          5       0.98      0.98      0.98        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       1.00      0.97      0.98        58\n",
      "          9       0.98      0.95      0.97        44\n",
      "\n",
      "avg / total       0.99      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(weights='uniform')\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.95      1.00      0.97        54\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       1.00      1.00      1.00        46\n",
      "          4       1.00      0.97      0.99        35\n",
      "          5       0.98      0.98      0.98        48\n",
      "          6       0.98      1.00      0.99        51\n",
      "          7       1.00      1.00      1.00        35\n",
      "          8       1.00      0.97      0.98        58\n",
      "          9       0.98      0.95      0.97        44\n",
      "\n",
      "avg / total       0.99      0.99      0.99       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(weights='distance')\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.87      0.83      0.85        54\n",
      "          2       0.97      0.68      0.80        44\n",
      "          3       0.89      0.67      0.77        46\n",
      "          4       1.00      0.74      0.85        35\n",
      "          5       0.91      0.90      0.91        48\n",
      "          6       0.91      0.96      0.93        51\n",
      "          7       0.65      1.00      0.79        35\n",
      "          8       0.60      0.86      0.71        58\n",
      "          9       0.94      0.70      0.81        44\n",
      "\n",
      "avg / total       0.86      0.83      0.83       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.96        35\n",
      "          1       0.80      0.81      0.81        54\n",
      "          2       0.90      0.84      0.87        44\n",
      "          3       0.77      0.74      0.76        46\n",
      "          4       0.88      0.86      0.87        35\n",
      "          5       0.82      0.85      0.84        48\n",
      "          6       0.94      0.94      0.94        51\n",
      "          7       0.89      0.89      0.89        35\n",
      "          8       0.71      0.78      0.74        58\n",
      "          9       0.78      0.73      0.75        44\n",
      "\n",
      "avg / total       0.84      0.84      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        35\n",
      "          1       0.85      0.83      0.84        54\n",
      "          2       0.93      0.93      0.93        44\n",
      "          3       0.98      0.87      0.92        46\n",
      "          4       0.97      0.91      0.94        35\n",
      "          5       0.95      0.77      0.85        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       0.83      1.00      0.91        35\n",
      "          8       0.85      0.86      0.85        58\n",
      "          9       0.71      0.84      0.77        44\n",
      "\n",
      "avg / total       0.90      0.89      0.89       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99        35\n",
      "          1       0.74      0.65      0.69        54\n",
      "          2       0.84      0.95      0.89        44\n",
      "          3       0.87      0.89      0.88        46\n",
      "          4       0.94      0.91      0.93        35\n",
      "          5       0.93      0.77      0.84        48\n",
      "          6       0.94      0.98      0.96        51\n",
      "          7       0.85      0.97      0.91        35\n",
      "          8       0.76      0.71      0.73        58\n",
      "          9       0.67      0.75      0.71        44\n",
      "\n",
      "avg / total       0.84      0.84      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.93      1.00      0.96        54\n",
      "          2       1.00      1.00      1.00        44\n",
      "          3       0.98      0.98      0.98        46\n",
      "          4       1.00      0.94      0.97        35\n",
      "          5       0.96      0.96      0.96        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       0.97      1.00      0.99        35\n",
      "          8       0.98      0.97      0.97        58\n",
      "          9       0.95      0.91      0.93        44\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = BaggingClassifier(KNeighborsClassifier(),\n",
    "                         max_samples=0.5, max_features=0.5)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93        35\n",
      "          1       0.90      0.98      0.94        54\n",
      "          2       0.93      0.98      0.96        44\n",
      "          3       0.92      0.96      0.94        46\n",
      "          4       0.92      0.94      0.93        35\n",
      "          5       0.88      0.94      0.91        48\n",
      "          6       0.98      0.98      0.98        51\n",
      "          7       0.92      0.97      0.94        35\n",
      "          8       0.94      0.78      0.85        58\n",
      "          9       0.97      0.75      0.85        44\n",
      "\n",
      "avg / total       0.92      0.92      0.92       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        35\n",
      "          1       0.93      1.00      0.96        54\n",
      "          2       0.98      1.00      0.99        44\n",
      "          3       0.96      0.96      0.96        46\n",
      "          4       1.00      0.94      0.97        35\n",
      "          5       0.98      0.96      0.97        48\n",
      "          6       0.96      1.00      0.98        51\n",
      "          7       0.83      1.00      0.91        35\n",
      "          8       1.00      0.88      0.94        58\n",
      "          9       0.97      0.89      0.93        44\n",
      "\n",
      "avg / total       0.96      0.96      0.96       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=10,\n",
    "                          max_depth=None,\n",
    "                          min_samples_split=2, \n",
    "                          random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.91      0.89        35\n",
      "          1       0.00      0.00      0.00        54\n",
      "          2       0.00      0.00      0.00        44\n",
      "          3       0.00      0.00      0.00        46\n",
      "          4       0.00      0.00      0.00        35\n",
      "          5       0.00      0.00      0.00        48\n",
      "          6       0.56      0.43      0.49        51\n",
      "          7       0.10      0.97      0.18        35\n",
      "          8       0.00      0.00      0.00        58\n",
      "          9       0.52      0.32      0.39        44\n",
      "\n",
      "avg / total       0.19      0.23      0.18       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=20)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      1.00      0.92        35\n",
      "          1       0.91      0.93      0.92        54\n",
      "          2       0.98      0.93      0.95        44\n",
      "          3       0.93      0.93      0.93        46\n",
      "          4       0.97      0.86      0.91        35\n",
      "          5       0.93      0.88      0.90        48\n",
      "          6       0.98      0.96      0.97        51\n",
      "          7       0.79      0.94      0.86        35\n",
      "          8       0.88      0.84      0.86        58\n",
      "          9       0.86      0.82      0.84        44\n",
      "\n",
      "avg / total       0.91      0.91      0.91       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=20)\n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        35\n",
      "          1       0.96      1.00      0.98        54\n",
      "          2       1.00      0.95      0.98        44\n",
      "          3       0.98      0.93      0.96        46\n",
      "          4       0.97      0.94      0.96        35\n",
      "          5       0.98      0.88      0.92        48\n",
      "          6       0.96      0.96      0.96        51\n",
      "          7       0.92      0.94      0.93        35\n",
      "          8       0.93      0.95      0.94        58\n",
      "          9       0.89      0.95      0.92        44\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.set_params(n_estimators=200, warm_start=True) \n",
    "clf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        35\n",
      "          1       0.96      1.00      0.98        54\n",
      "          2       1.00      0.95      0.98        44\n",
      "          3       0.98      0.93      0.96        46\n",
      "          4       0.97      0.94      0.96        35\n",
      "          5       0.98      0.88      0.92        48\n",
      "          6       0.96      0.96      0.96        51\n",
      "          7       0.92      0.94      0.93        35\n",
      "          8       0.93      0.95      0.94        58\n",
      "          9       0.89      0.95      0.92        44\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), \n",
    "                                    ('rf', clf2), \n",
    "                                    ('gnb', clf3)],\n",
    "                        voting='hard')\n",
    "eclf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96        35\n",
      "          1       0.96      1.00      0.98        54\n",
      "          2       1.00      0.95      0.98        44\n",
      "          3       0.98      0.93      0.96        46\n",
      "          4       0.97      0.94      0.96        35\n",
      "          5       0.98      0.88      0.92        48\n",
      "          6       0.96      0.96      0.96        51\n",
      "          7       0.92      0.94      0.93        35\n",
      "          8       0.93      0.95      0.94        58\n",
      "          9       0.89      0.95      0.92        44\n",
      "\n",
      "avg / total       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), \n",
    "                                    ('rf', clf2), \n",
    "                                    ('gnb', clf3)], \n",
    "                        voting='soft', \n",
    "                        weights=[2,1,2])\n",
    "eclf.fit(x_train,y_train)\n",
    "predict = clf.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] lr__C=1.0, rf__n_estimators=20 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... lr__C=1.0, rf__n_estimators=20, total=   0.2s\n",
      "[CV] lr__C=1.0, rf__n_estimators=20 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... lr__C=1.0, rf__n_estimators=20, total=   0.3s\n",
      "[CV] lr__C=1.0, rf__n_estimators=20 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... lr__C=1.0, rf__n_estimators=20, total=   0.1s\n",
      "[CV] lr__C=1.0, rf__n_estimators=200 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. lr__C=1.0, rf__n_estimators=200, total=   1.1s\n",
      "[CV] lr__C=1.0, rf__n_estimators=200 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. lr__C=1.0, rf__n_estimators=200, total=   0.8s\n",
      "[CV] lr__C=1.0, rf__n_estimators=200 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. lr__C=1.0, rf__n_estimators=200, total=   0.9s\n",
      "[CV] lr__C=100.0, rf__n_estimators=20 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. lr__C=100.0, rf__n_estimators=20, total=   0.2s\n",
      "[CV] lr__C=100.0, rf__n_estimators=20 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. lr__C=100.0, rf__n_estimators=20, total=   0.2s\n",
      "[CV] lr__C=100.0, rf__n_estimators=20 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. lr__C=100.0, rf__n_estimators=20, total=   0.4s\n",
      "[CV] lr__C=100.0, rf__n_estimators=200 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ lr__C=100.0, rf__n_estimators=200, total=   1.0s\n",
      "[CV] lr__C=100.0, rf__n_estimators=200 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ lr__C=100.0, rf__n_estimators=200, total=   1.2s\n",
      "[CV] lr__C=100.0, rf__n_estimators=200 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ lr__C=100.0, rf__n_estimators=200, total=   1.2s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        35\n",
      "          1       0.93      0.93      0.93        54\n",
      "          2       1.00      0.95      0.98        44\n",
      "          3       0.97      0.83      0.89        46\n",
      "          4       0.97      0.91      0.94        35\n",
      "          5       0.91      0.90      0.91        48\n",
      "          6       0.96      0.98      0.97        51\n",
      "          7       0.76      1.00      0.86        35\n",
      "          8       0.82      0.91      0.86        58\n",
      "          9       0.95      0.80      0.86        44\n",
      "\n",
      "avg / total       0.92      0.92      0.92       450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\RUANJIAN\\Anaconda3\\Anaconda3_3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), \n",
    "                                    ('rf', clf2), \n",
    "                                    ('gnb', clf3)], \n",
    "                        voting='soft', \n",
    "                        weights=[2,1,2])\n",
    "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200],}\n",
    "grid = GridSearchCV(estimator=eclf,verbose=2,param_grid=params, cv=3)\n",
    "grid = grid.fit(x_train,y_train)\n",
    "predict = grid.predict(x_test)\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
